{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "qMY3ei6Kqn4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from argparse import Namespace, ArgumentParser\n",
        "\n",
        "# from src.constants import DATA_DIR, TRAIN_FILE, VALID_FILE, TEST_FILE, CONTEXT_FILE\n",
        "# from src.constants import MC_TRAIN_FILE, MC_VALID_FILE, MC_TEST_FILE, QA_TRAIN_FILE, QA_VALID_FILE, QA_TEST_FILE\n",
        "# from src.utils import load_json, save_json, process_mc_data, process_qa_data"
      ],
      "metadata": {
        "id": "J4dCiIw9qnfO"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing"
      ],
      "metadata": {
        "id": "7yJGW0MZqd18"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTu8NEqueDHR"
      },
      "outputs": [],
      "source": [
        "# Convert to dataset\n",
        "\n",
        "def parse_arguments() -> Namespace:\n",
        "    parser = ArgumentParser(description=\"Preprocessing\")\n",
        "\n",
        "    parser.add_argument(\"--preprocess\", type=str, default=\"mc\",\n",
        "                        help=\"multiple choice or question answering\")\n",
        "    parser.add_argument(\"--inference\", action=\"store_true\",\n",
        "                        help=\"only for test data\")\n",
        "    parser.add_argument(\"--test_data\", type=str, default=None,\n",
        "                        help=\"path of test data\")\n",
        "    parser.add_argument(\"--context_data\", type=str, default=None,\n",
        "                        help=\"path of context data\")\n",
        "    return parser.parse_args()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_fun = {\n",
        "        \"mc\": process_mc_data,\n",
        "        \"qa\": process_qa_data,\n",
        "    }\n",
        "\n",
        "    args = parse_arguments()\n",
        "\n",
        "    if args.inference:\n",
        "        context = load_json(args.context_data)\n",
        "        test_data = load_json(args.test_data)\n",
        "        test_list = [process_fun[args.preprocess](data, context, answer=False) for data in test_data]\n",
        "        save_json(test_list, os.path.join(DATA_DIR, MC_TEST_FILE))\n",
        "    else:\n",
        "        context = load_json(os.path.join(DATA_DIR, CONTEXT_FILE))\n",
        "        train_data = load_json(os.path.join(DATA_DIR, TRAIN_FILE))\n",
        "        train_list = [process_fun[args.preprocess](data, context, answer=True) for data in train_data]\n",
        "\n",
        "        save_json(train_list, os.path.join(DATA_DIR, MC_TRAIN_FILE if args.preprocess==\"mc\" else QA_TRAIN_FILE))\n",
        "\n",
        "        valid_data = load_json(os.path.join(DATA_DIR, VALID_FILE))\n",
        "        valid_list = [process_fun[args.preprocess](data, context, answer=True) for data in valid_data]\n",
        "        save_json(valid_list, os.path.join(DATA_DIR, MC_VALID_FILE if args.preprocess==\"mc\" else QA_VALID_FILE))\n",
        "\n",
        "        if args.preprocess == \"mc\":\n",
        "            test_data = load_json(os.path.join(DATA_DIR, TEST_FILE))\n",
        "            test_list = [process_fun[args.preprocess](data, context, answer=False) for data in test_data]\n",
        "            save_json(test_list, os.path.join(DATA_DIR, MC_TEST_FILE))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a5I5ukjHq1zb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}